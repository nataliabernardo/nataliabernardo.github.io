---
layout: post
title:  "Natural Language Processing on Aesthetic Procedure Reviews"
featured-img: LDA
---

# Predicting what user reviews are about with Topic Modeling and Sentiment Analysis

A few years ago, I was searching for a skin treatment and found this website called [Realself](https://www.realself.com). It's the best source of information for those who are planning to do some aesthetic procedure, where thousands of users share their experience on treatments, like writing a diary. 

After reading many reviews, I found four different treatments that offered similar outcomes based in the before and after pictures and chose the one that required less sessions to achieve the desired result. It was the most expensive and with longer downtime, however, provided faster results.

There are two different types of reviews in Realself: (1) for doctors and (2) for procedures. Pacients review doctors for 9 different categories and procedures for 1 category ("worth it", "not worth it" or "not sure"), as you can see in the image below.


 <p align="center"> <img src="/assets/article_images/project_4/reviews.jpg" width="95%"></p>


So I thought it would be interesting to uncover what customers talk more about in those long posts. For this task, I used a topic modelling method called [Latent Dirichlet Allocation (LDA)](https://en.wikipedia.org/wiki/Latent_Dirichlet_allocation), a Natural Language Processing (NLP) tool that can automatically identify topics from a corpus. A “topic” consists of a group of words that frequently occur together. 

Having the topics defined, I decided to predict how the users would rate their experience on those themes, in other words, I simulated the ratings for the potential subcategories of the procedures (such as for the doctors' reviews) based on user's sentiments. I used [Textblob](textblob.readthedocs.io/en/dev/) Sentiment for classifying each sentence of the posts as "negative" or "positive".

<p align="center"> <img src="/assets/article_images/project_4/workflow.png" width="100%"></p>

The results were presented in an interactive viz ([click here](https://nataliabernardo.github.io/assets/viz/index.html)), where you can explore the ratings, topics by procedure and sentiment over time.

### 1. Data collection and cleaning

I extracted all posts (53,547 posts from 17,270 unique users) of all reviews from 3 different procedures: botox, rhinoplasty and coolsculpting. I used BeatifulSoup and Selenium for obtaining the data, and stored it in MongoDB.

Four steps are important for any natural language processing project:

1. tokenize - split up the document (post) into words
2. lemmatize - get each word down to its root form (i.e. walking -> walk, better -> good)
3. remove stop words - the most common words in a language (i.e. the, is, at, which)
4. vectorize - transform text into a vector of numbers

I used the Python's libraries [NLTK](http://www.nltk.org) and sckit-learn's [CountVectorizer](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html), that takes each word in each document and counts the number of times the word appears.

Using CountVectorizer, I built a word matrix choosing a max_df of 80% and min_df of 10, meaning that the matrix would exclude words that appeared in more than 80% of the texts (to avoid commonly used terms) and less than 10 times. I also chose an ngram range of (1, 3) -  pairs or triplets of words that show up together - to be able to capture terms of two or three words  commonly used together.

### 2. LDA to identify "hidden" topics in reviews

I experiemented with different topic modelling techniques: LDA, non-negative matrix factorization (NMF) and k-means, and LDA's topics were easier to interpret. In this model, each topic from a corpus of text documents is defined as a multinomial distribution over a word dictionary with words drawn from a [Dirichlet distribution](https://en.wikipedia.org/wiki/Dirichlet_distribution). 

However, it's not always an easy task. It requires human judgments to assign a category to the topic by looking at the words in it. After carefully examining the results, I visually identified the topics and, as expected, they were peculiar for each treatment:

<p align="center"> <img src="/assets/article_images/project_4/all_topics.png" width="100%"></p>

I realized that despite having different themes, the reviews could be divided into 3 big topics: Procedure, Recovery and Results.

<p align="center"> <img src="/assets/article_images/project_4/topics.jpg" width="100%"></p>

The next step was to assign ratings for each one of those aggregated topics.


### 3. Sentiment Analysis to assign ratings for topics

One possible approach to define the rating for the topic is the percent positive comments in each treatment, similar to Rotten Tomatoes scores. For this task I tried Vader and TextBlob, and the later provided better results: "not worth it" reviews had more negative comments, while "worth it" reviews had more positive comments.

<p align="center"> <img src="/assets/article_images/project_4/rating.jpg" width="100%"></p>

### 4. Demo

<iframe src="{{ site.url }}/assets/viz/index.html" width="900" height="600" frameBorder="0.5"></iframe>

### Conclusions & Future work

Probabilistic topic models have become popular tools for the unsupervised analysis of large document collections. These models posit a set of latent topics, multinomial distributions over words, and assume that each document can be described as a mixture of these topics. 
